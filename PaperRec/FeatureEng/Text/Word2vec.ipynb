{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import csv\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import logging\n",
    "import re\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "info = pd.read_csv('/home/duyongkang/aminer/aminer.paper.info.csv')\n",
    "auth_info = pd.read_csv('/home/duyongkang/aminer/aminer.author.expertise.tag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先把全部学者编号和标签拿出来放到list中\n",
    "ppr_list = info['paper_id'].values.tolist()             # 论文列表\n",
    "text_list = info['text'].values.tolist()                # 文本列表\n",
    "auth_list = auth_info['author_id'].values.tolist()      # 作者列表\n",
    "exper_list = auth_info['expertise_tag'].values.tolist() # 专长列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去掉标点符号并分割成单词\n",
    "lists_new = []\n",
    "for list in exper_list:\n",
    "#     string = re.sub(\"[\\s+\\.\\;\\!\\/_,$%^)<}]*•≥=[:|{>(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \" \", list)\n",
    "    string = re.sub(\"\\W\", \" \", list)\n",
    "    lists_new.append(string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "638643"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_c = 0\n",
    "for i in range(len(lists_new)):\n",
    "    count_c += len(lists_new[i])\n",
    "count_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['organization', 'quality', 'models']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(lists_new)):\n",
    "#     for j in range(len(lists_new[i])):\n",
    "#         if( 'system' in lists_new[i][j]):\n",
    "#             print('!')\n",
    "#         test_str = re.search(r\"\\W\",lists_new[i][j])\n",
    "#         if test_str!=None:\n",
    "#             print('i',i,' ','j',j,' ',lists_new[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file = 'text.txt'\n",
    "# with open(output_file,'w') as f:\n",
    "#     for i in range(len(lists_new)):\n",
    "#         outline = ''\n",
    "#         for word in lists_new[i]:\n",
    "#             word += ' '\n",
    "#             outline += word\n",
    "#         f.write(outline + \"\\n\")\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用文本信息构建w2v模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class callback(CallbackAny2Vec):\n",
    "#     '''Callback to print loss after each epoch.'''\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self.epoch = 0\n",
    "\n",
    "#     def on_epoch_end(self, model):\n",
    "#         loss = model.get_latest_training_loss()\n",
    "#         print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "#         self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Word2Vec(lists_new, sg=1, size=100, window=5,  min_count=1,  negative=3, sample=0.001, hs=1, workers=10, alpha=0.01, compute_loss=True,callbacks=[callback()])\n",
    "# model.save(\"w2v.model\")\n",
    "# model = Word2Vec.load('w2v.model')\n",
    "# model.train(lists_new,total_examples=len(ppr_list),epochs=20,compute_loss=True,callbacks=[callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('/home/duyongkang/GloVe/vectors.txt',header=None)\n",
    "# data = data.drop([0])\n",
    "data.columns = ['vector']\n",
    "data = pd.DataFrame(data.vector.str.split(' ',1).tolist(), columns = ['word','vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>-0.861408 -0.628075 0.043010 1.051666 1.215059...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>-0.777877 -0.581980 -0.316073 0.113544 1.49328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>0.186485 -0.593945 -0.567363 0.008803 1.901995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>0.297141 -0.679280 -0.371810 0.498104 1.253722...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>0.101414 -1.457081 0.019926 0.647328 1.671532 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32212</th>\n",
       "      <td>zrp</td>\n",
       "      <td>0.388301 0.213353 -0.018898 -0.168224 -0.06187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32213</th>\n",
       "      <td>zs</td>\n",
       "      <td>0.045164 0.112919 0.416550 -0.237265 -0.046351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32214</th>\n",
       "      <td>zsccmos</td>\n",
       "      <td>-0.080776 0.227994 0.132621 0.081387 -0.221894...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32215</th>\n",
       "      <td>zunic</td>\n",
       "      <td>-0.059311 0.440690 -0.047665 -0.037580 -0.6641...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32216</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0.066333 0.230750 0.061137 -0.129546 -0.307172...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32217 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word                                             vector\n",
       "0          the  -0.861408 -0.628075 0.043010 1.051666 1.215059...\n",
       "1           of  -0.777877 -0.581980 -0.316073 0.113544 1.49328...\n",
       "2          and  0.186485 -0.593945 -0.567363 0.008803 1.901995...\n",
       "3            a  0.297141 -0.679280 -0.371810 0.498104 1.253722...\n",
       "4           to  0.101414 -1.457081 0.019926 0.647328 1.671532 ...\n",
       "...        ...                                                ...\n",
       "32212      zrp  0.388301 0.213353 -0.018898 -0.168224 -0.06187...\n",
       "32213       zs  0.045164 0.112919 0.416550 -0.237265 -0.046351...\n",
       "32214  zsccmos  -0.080776 0.227994 0.132621 0.081387 -0.221894...\n",
       "32215    zunic  -0.059311 0.440690 -0.047665 -0.037580 -0.6641...\n",
       "32216    <unk>  0.066333 0.230750 0.061137 -0.129546 -0.307172...\n",
       "\n",
       "[32217 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    list_1 = data.vector[i].split(' ')\n",
    "#     list_1.pop()\n",
    "    list_1 = [float(x) for x in list_1]\n",
    "    data.vector[i] = list_1\n",
    "    if i%5000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = data[['word','vector']].set_index('word').to_dict()['vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic['research'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算学者向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并每个学者的专长\n",
    "exper_dic = {}   #key为学者编号，value为专长\n",
    "for i in range(len(auth_list)):\n",
    "    node = \"a\"+str(auth_list[i])\n",
    "    if node not in exper_dic:\n",
    "        exper_dic[node] = []\n",
    "    temp = exper_list[i].split()\n",
    "    exper_dic[node].extend(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#专长向量化\n",
    "exper_vec = {}\n",
    "\n",
    "for key in exper_dic:              \n",
    "    exper_vec[key] = []\n",
    "    for i in range(100):\n",
    "        value = 0\n",
    "        count = 0\n",
    "        for doc in exper_dic[key]:\n",
    "            try:\n",
    "                vec = dic[doc][i]\n",
    "                value+=vec\n",
    "            except:\n",
    "                count+=1\n",
    "                continue\n",
    "        value /= (len(exper_dic[key]) - count)\n",
    "        exper_vec[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成dataframe文件\n",
    "df_a = pd.DataFrame(pd.Series(exper_vec), columns=['vector'])\n",
    "df_a = df_a.reset_index().rename(columns = {'index':'node'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_a.vector[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算论文向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建一个字典，key为论文编号，value为text\n",
    "ppr_dic = {}\n",
    "for i in range(len(ppr_list)):\n",
    "    node = \"p\"+str(ppr_list[i])\n",
    "    if node not in ppr_dic:\n",
    "        ppr_dic[node] = []\n",
    "    ppr_dic[node].extend(lists_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成论文的文本特征\n",
    "ppr_vec = {}\n",
    "for key in ppr_dic:\n",
    "    ppr_vec[key] = []\n",
    "    for i in range(100):\n",
    "        value = 0\n",
    "        count = 0\n",
    "        for doc in ppr_dic[key]:\n",
    "            try:\n",
    "                vec = dic[doc][i]\n",
    "            except:\n",
    "                count+=1\n",
    "                continue\n",
    "            value+=vec\n",
    "        value /= (len(ppr_dic[key])-count)\n",
    "        ppr_vec[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成dataframe文件\n",
    "df_p = pd.DataFrame(pd.Series(ppr_vec), columns=['vector'])\n",
    "df_p = df_p.reset_index().rename(columns = {'index':'node'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并作者向量和论文向量\n",
    "result = df_a.append(df_p)\n",
    "result.to_pickle('Glove.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
